<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    
    <title>Hive的分区表 | 云筑小站</title>
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <meta name="description" content="脚踏实地、仰望星空;低头走路，抬头看天;既练轻功，也练内功。">

    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Hive的分区表 | 云筑小站">
    <meta name="twitter:description" content="脚踏实地、仰望星空;低头走路，抬头看天;既练轻功，也练内功。">

    <meta property="og:type" content="article">
    <meta property="og:title" content="Hive的分区表 | 云筑小站">
    <meta property="og:description" content="脚踏实地、仰望星空;低头走路，抬头看天;既练轻功，也练内功。">

    
    <meta name="author" content="XieJM">
    
    <link rel="stylesheet" href="/css/vno.css">
    <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css">

    
    <link rel="icon" href="/images/favicon.png">
    

    
    <link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
    
    
    <meta name="generator" content="hexo"/>
    
    <link rel="alternate" type="application/rss+xml" title="云筑小站" href="/atom.xml">
    

    <link rel="canonical" href="http://xiejm.com/Hive/Hive--partition.html"/>

    
</head>

<body class="home-template no-js">

    <span class="mobile btn-mobile-menu">
        <i class="fa fa-list btn-mobile-menu__icon"></i>
        <i class="fa fa-angle-up btn-mobile-close__icon hidden"></i>
    </span>

    
<header class="panel-cover panel-cover--collapsed" style="background-image: url(/images/background-cover.jpg)">
  <div class="panel-main">
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        <a href="/" title="前往 云筑小站 的主页"><img src="/images/logo.png" width="80" alt="云筑小站 logo" class="panel-cover__logo logo" /></a>
        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage for 云筑小站">云筑小站</a></h1>
        
        <span class="panel-cover__subtitle panel-subtitle">分享技术 记录生活</span>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">脚踏实地、仰望星空;低头走路，抬头看天;既练轻功，也练内功。</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        
        <div class="navigation-wrapper">
          <div>
          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              <li class="navigation__item"><a href="/#blog" title="访问博客" class="blog-button">文章</a></li>
            
              <li class="navigation__item"><a href="/archives">归档</a></li>
            
            </ul>
          </nav>
          </div>
          <div>
          <nav class="cover-navigation navigation--social">
  <ul class="navigation">

  <!-- Weibo-->
  

  <!-- Github -->
  
  <li class="navigation__item">
    <a href="https://github.com/xjmhz" title="查看我的GitHub主页" target="_blank">
      <i class='social fa fa-github'></i>
      <span class="label">Github</span>
    </a>
  </li>


<!-- Stack Overflow -->
        

  <!-- Google Plus -->
  

<!-- Facebook -->


<!-- Twitter -->

<!-- instagram -->


  <li class="navigation__item">
    <a href="/atom.xml" title="RSS" target="_blank">
      <i class='social fa fa-rss'></i>
      <span class="label">RSS</span>
    </a>
  </li>



  </ul>
</nav>

          </div>
        </div>

      </div>

    </div>

    <div class="panel-cover--overlay cover-disabled"></div>
  </div>
</header>


    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <article class="post-container post-container--single">

  <header class="post-header">
    <div class="post-meta">
      <time datetime="2017-10-09T07:53:44.000Z" class="post-list__meta--date date">2017-10-09</time>
 &#8226; <span class="post-meta__tags tags">分类&nbsp;
  <a class="tag-link" href="/tags/Hive/">Hive</a>

</span>
    </div>
    <h1 class="post-title">Hive的分区表</h1>
  </header>

  <section class="post">
    <p>本文主要是对Hive分区表的总结，Hive分区表有三种类型：静态单级分区表、静态多级分区表、动态分区表<br>在实际工作中Hive的分区表应用非常多，特别是动态分区表。</p>
<p>直接上干货！</p>
<h2 id="静态分区表的使用"><a href="#静态分区表的使用" class="headerlink" title="静态分区表的使用"></a>静态分区表的使用</h2><h3 id="单级分区表创建"><a href="#单级分区表创建" class="headerlink" title="单级分区表创建"></a>单级分区表创建</h3><p>新建一个分区表，并导入数据。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> order_partition(</span><br><span class="line">order_number <span class="keyword">string</span>,</span><br><span class="line">event_time <span class="keyword">string</span></span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span>(event_month <span class="keyword">string</span>,<span class="keyword">day</span> <span class="keyword">STRING</span>)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/root/order_created.txt'</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> order_partition <span class="keyword">PARTITION</span>(event_month=<span class="string">'201709'</span>);</span><br><span class="line"></span><br><span class="line">Loading data to table default.order_partition partition (event_month=201709)</span><br><span class="line">Partition default.order_partition&#123;event_month=201709&#125; stats: [numFiles=1, numRows=0, totalSize=208, rawDataSize=0]</span><br><span class="line">OK</span><br><span class="line">Time taken: 1.121 seconds</span><br></pre></td></tr></table></figure>
<p>从上面的语句可以看出与创建普通表的区别是多了<code>PARTITIONED BY</code></p>
<p>在创建表时候，使用<code>PARTITIONED BY</code>关键字来指定该表为分区表，后面括号中指定了分区的字段和类型，分区字段可以有多个，在HDFS中对应多级目录。</p>
<p>以上语句如果报错显示乱码，解决办法：<br>在MySQL中修改Hive的元数据 数据库中的分区表的编码</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">database</span> hive3 <span class="built_in">character</span> <span class="keyword">set</span> latin1;</span><br><span class="line"><span class="keyword">use</span> hive3;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> <span class="keyword">PARTITIONS</span> <span class="keyword">convert</span> <span class="keyword">to</span> <span class="built_in">character</span> <span class="keyword">set</span> latin1;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> PARTITION_KEYS <span class="keyword">convert</span> <span class="keyword">to</span> <span class="built_in">character</span> <span class="keyword">set</span> latin1;</span><br></pre></td></tr></table></figure>
<p>用beeline查询分区表记录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">0: jdbc:hive2://hadoop001:10000/default&gt; select * from order_partition;</span><br><span class="line"></span><br><span class="line">INFO  : OK</span><br><span class="line">+-------------------------------+-----------------------------+------------------------------+--+</span><br><span class="line">| order_partition.order_number  | order_partition.event_time  | order_partition.event_month  |</span><br><span class="line">+-------------------------------+-----------------------------+------------------------------+--+</span><br><span class="line">| 10703007267488                | 2014-05-01 06:01:12.334+01  | 201709                       |</span><br><span class="line">| 10101043505096                | 2014-05-01 07:28:12.342+01  | 201709                       |</span><br><span class="line">| 10103043509747                | 2014-05-01 07:50:12.33+01   | 201709                       |</span><br><span class="line">| 10103043501575                | 2014-05-01 09:27:12.33+01   | 201709                       |</span><br><span class="line">| 10104043514061                | 2014-05-01 09:03:12.324+01  | 201709                       |</span><br><span class="line">+-------------------------------+-----------------------------+------------------------------+--+</span><br><span class="line">5 rows selected (0.141 seconds)</span><br></pre></td></tr></table></figure>
<p>查看下order_partition.txt ，用来与表做对比</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ cat data/order_created.txt</span><br><span class="line">10703007267488	2014-05-01 06:01:12.334+01</span><br><span class="line">10101043505096	2014-05-01 07:28:12.342+01</span><br><span class="line">10103043509747	2014-05-01 07:50:12.33+01</span><br><span class="line">10103043501575	2014-05-01 09:27:12.33+01</span><br><span class="line">10104043514061	2014-05-01 09:03:12.324+01</span><br></pre></td></tr></table></figure>
<p>从<code>select * from order_partition;</code> 和 <code>cat data/order_created.txt</code>的结果对比得出一个结果：<br>分区列不是表中的一个实际的列，其实是一个伪列</p>
<h3 id="使用ALTER-TABLE修改分区"><a href="#使用ALTER-TABLE修改分区" class="headerlink" title="使用ALTER TABLE修改分区"></a>使用ALTER TABLE修改分区</h3><p>如果我们在HDFS中创建了分区表目录，并通过HDFS导入数据到该目录，那么在Hive端是查询不到该分区表的数据的<br>我们需要关联该数据</p>
<p>使用下列语句,具体语法看官网wiki</p>
<p>方法一：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> order_partition <span class="keyword">ADD</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> <span class="keyword">PARTITION</span>(event_month=<span class="string">'201709'</span>)</span><br></pre></td></tr></table></figure>
<p>方法二：</p>
<p>作用：将没有metastore中的分区表信息，添加到metastore中</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MSCK <span class="keyword">REPAIR</span> order_partition; 不推荐使用，太暴力了</span><br></pre></td></tr></table></figure>
<p>为什么暴力：<br>MSCK的操作是表级别的，<br>假设metastore数据存了一年，一天1个分区，一年就是365分区，这样MSCK一执行很可能把其他不需要刷新元数据信息的表也给刷新了，所以存在风险。</p>
<h3 id="使用INSERT添加分区"><a href="#使用INSERT添加分区" class="headerlink" title="使用INSERT添加分区"></a>使用INSERT添加分区</h3><p>往分区中追加数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> order_partition <span class="keyword">PARTITION</span> (<span class="keyword">month</span> = <span class="string">'2017-10'</span>,<span class="keyword">day</span> = <span class="string">'2017-10-01'</span>)</span><br></pre></td></tr></table></figure>
<p>覆盖分区数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> overwrite <span class="keyword">TABLE</span> order_partition <span class="keyword">PARTITION</span> (<span class="keyword">month</span> = <span class="string">'2017-10'</span>,<span class="keyword">day</span> = <span class="string">'2017-10-01'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="查询分区表信息"><a href="#查询分区表信息" class="headerlink" title="查询分区表信息"></a>查询分区表信息</h3><p>查看一个分区对应的HDFS路径信息</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">partitions</span> order_partition;</span><br><span class="line"></span><br><span class="line">OK</span><br><span class="line">event_month=201709</span><br><span class="line">Time taken: 0.041 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure>
<h3 id="静态多级分区表"><a href="#静态多级分区表" class="headerlink" title="静态多级分区表"></a>静态多级分区表</h3><p>上面已经说了静态分区表的一些使用方法，这里在补充一个多级分区表的创建</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> order_mulit_partition(</span><br><span class="line">order_number <span class="keyword">string</span>,</span><br><span class="line">event_time <span class="keyword">string</span></span><br><span class="line">)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span>(event_month <span class="keyword">string</span>,<span class="keyword">day</span> <span class="keyword">STRING</span>)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/root/order_created.txt'</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> order_partition <span class="keyword">PARTITION</span>(event_month=<span class="string">'201709'</span>,<span class="keyword">day</span>=<span class="string">'2017-09-15'</span>);</span><br></pre></td></tr></table></figure>
<p>创建分区表返回信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Loading data to table default.order_mulit_partition partition (event_month=201709, day=2017-09-15)</span><br><span class="line">Partition default.order_mulit_partition&#123;event_month=201709, day=2017-09-15&#125; stats: [numFiles=1, numRows=0, totalSize=208, rawDataSize=0]</span><br><span class="line">OK</span><br><span class="line">Time taken: 1.121 seconds</span><br><span class="line">`</span><br></pre></td></tr></table></figure>
<p>说明：上面的表order_mulit_partition分区event_month=’201709’,day=’2017-09-15’对应HDFS上的路径为：/user/hive/warehouse/default.db/order_partition/event_month=201709/day=2017-09-15/，当查询中指定了event_month=’201709’ AND dday=’2017-09-15’,MapReduce直接从该目录中读取数据，如果只指定了event_month=’201709’，那么MapReduce将/month=2015-06/下所有的子目录都作为Input。</p>
<p>查看表</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hive (default)&gt; select * from order_mulit_partition;</span><br><span class="line">OK</span><br><span class="line">10703007267488	2014-05-01 06:01:12.334+01	201709	2017-09-15</span><br><span class="line">10101043505096	2014-05-01 07:28:12.342+01	201709	2017-09-15</span><br><span class="line">10103043509747	2014-05-01 07:50:12.33+01	201709	2017-09-15</span><br><span class="line">10103043501575	2014-05-01 09:27:12.33+01	201709	2017-09-15</span><br><span class="line">10104043514061	2014-05-01 09:03:12.324+01	201709	2017-09-15</span><br><span class="line">Time taken: 0.325 seconds, Fetched: 5 row(s)</span><br></pre></td></tr></table></figure>
<p>可以看到有两个字段,再执行一次载入数据</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/root/order_created.txt'</span> overwrite <span class="keyword">into</span> <span class="keyword">table</span> order_mulit_partition <span class="keyword">PARTITION</span>(event_month=<span class="string">'201709'</span>,<span class="keyword">day</span>=<span class="string">'2017-09-16'</span>);</span><br></pre></td></tr></table></figure>
<p>查看表</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hive (default)&gt; select * from order_mulit_partition;</span><br><span class="line">OK</span><br><span class="line">10703007267488	2014-05-01 06:01:12.334+01	201709	2017-09-15</span><br><span class="line">10101043505096	2014-05-01 07:28:12.342+01	201709	2017-09-15</span><br><span class="line">10103043509747	2014-05-01 07:50:12.33+01	201709	2017-09-15</span><br><span class="line">10103043501575	2014-05-01 09:27:12.33+01	201709	2017-09-15</span><br><span class="line">10104043514061	2014-05-01 09:03:12.324+01	201709	2017-09-15</span><br><span class="line">10703007267488	2014-05-01 06:01:12.334+01	201709	2017-09-16</span><br><span class="line">10101043505096	2014-05-01 07:28:12.342+01	201709	2017-09-16</span><br><span class="line">10103043509747	2014-05-01 07:50:12.33+01	201709	2017-09-16</span><br><span class="line">10103043501575	2014-05-01 09:27:12.33+01	201709	2017-09-16</span><br><span class="line">10104043514061	2014-05-01 09:03:12.324+01	201709	2017-09-16</span><br></pre></td></tr></table></figure>
<p>再来查下order_mulit_partition分区表信息</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">partitions</span> order_mulit_partition;</span><br><span class="line">OK</span><br><span class="line">event_month=201709/day=2017-09-15</span><br><span class="line">event_month=201709/day=2017-09-16</span><br><span class="line">Time taken: 0.033 seconds, Fetched: 2 row(s)</span><br></pre></td></tr></table></figure>
<p>在多分区使用的时候注意：每个分区字段要写明，顺序等等</p>
<h2 id="动态分区表"><a href="#动态分区表" class="headerlink" title="动态分区表"></a>动态分区表</h2><p><strong>这种方式在工作中才是常用的</strong>,<br>动态分区无需手工指定数据导入的具体分区，<br>而由select语句中的字段自行决定导出到哪一个分区中，<br>并自动创建相应的分区，使用上更加方便便捷。</p>
<p>假设有一个需求：按照不同部门作为分区导入数据到目标表</p>
<p>如果这张表有很多列，全部这样写SQL 语句效率太差,那么我们就可以使用动态分区表</p>
<h3 id="创建分区表"><a href="#创建分区表" class="headerlink" title="创建分区表"></a>创建分区表</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> emp_dynamic_partition(</span><br><span class="line">empno <span class="built_in">int</span>, </span><br><span class="line">ename <span class="keyword">string</span>, </span><br><span class="line">job <span class="keyword">string</span>, </span><br><span class="line">mgr <span class="built_in">int</span>, </span><br><span class="line">hiredate <span class="keyword">string</span>, </span><br><span class="line">sal <span class="keyword">double</span>, </span><br><span class="line">comm <span class="keyword">double</span>)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span>(deptno <span class="built_in">int</span>)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br></pre></td></tr></table></figure>
<h3 id="使用动态方式导入数据"><a href="#使用动态方式导入数据" class="headerlink" title="使用动态方式导入数据"></a>使用动态方式导入数据</h3><p>导入数据前先设置动态分区的模式：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hive (default)&gt; <span class="built_in">set</span> hive.exec.dynamic.partition.mode=nonstrict;</span><br></pre></td></tr></table></figure>
<p>开始导入数据</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hive (default)&gt; insert into table emp_dynamic_partition partition(deptno)</span><br><span class="line">              &gt; select empno , ename , job , mgr , hiredate , sal , comm, deptno from emp;</span><br><span class="line">Query ID = hadoop_20170925072626_d98526f6-67aa-4593-b723-5a5bd4e422a8</span><br><span class="line">Total <span class="built_in">jobs</span> = 3</span><br><span class="line">Launching Job 1 out of 3</span><br><span class="line">Number of reduce tasks is <span class="built_in">set</span> to 0 since there<span class="string">'s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1506263819287_0002, Tracking URL = http://hadoop001:8088/proxy/application_1506263819287_0002/</span></span><br><span class="line"><span class="string">Kill Command = /home/hadoop/app/hadoop//bin/hadoop job  -kill job_1506263819287_0002</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2017-09-25 07:28:03,866 Stage-1 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2017-09-25 07:28:10,214 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.37 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 2 seconds 370 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1506263819287_0002</span></span><br><span class="line"><span class="string">Stage-4 is selected by condition resolver.</span></span><br><span class="line"><span class="string">Stage-3 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Stage-5 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Moving data to: hdfs://hadoop001:9000/user/hive/warehouse/emp_dynamic_partition/.hive-staging_hive_2017-09-25_07-27-57_012_6944175324299480316-1/-ext-10000</span></span><br><span class="line"><span class="string">Loading data to table default.emp_dynamic_partition partition (deptno=null)</span></span><br><span class="line"><span class="string">	 Time taken for load dynamic partitions : 542</span></span><br><span class="line"><span class="string">	Loading partition &#123;deptno=20&#125;</span></span><br><span class="line"><span class="string">	Loading partition &#123;deptno=__HIVE_DEFAULT_PARTITION__&#125;</span></span><br><span class="line"><span class="string">	Loading partition &#123;deptno=10&#125;</span></span><br><span class="line"><span class="string">	Loading partition &#123;deptno=30&#125;</span></span><br><span class="line"><span class="string">	 Time taken for adding to write entity : 3</span></span><br><span class="line"><span class="string">Partition default.emp_dynamic_partition&#123;deptno=10&#125; stats: [numFiles=1, numRows=3, totalSize=130, rawDataSize=127]</span></span><br><span class="line"><span class="string">Partition default.emp_dynamic_partition&#123;deptno=20&#125; stats: [numFiles=1, numRows=5, totalSize=214, rawDataSize=209]</span></span><br><span class="line"><span class="string">Partition default.emp_dynamic_partition&#123;deptno=30&#125; stats: [numFiles=1, numRows=6, totalSize=275, rawDataSize=269]</span></span><br><span class="line"><span class="string">Partition default.emp_dynamic_partition&#123;deptno=__HIVE_DEFAULT_PARTITION__&#125; stats: [numFiles=1, numRows=1, totalSize=44, rawDataSize=43]</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched: </span></span><br><span class="line"><span class="string">Stage-Stage-1: Map: 1   Cumulative CPU: 2.37 sec   HDFS Read: 4705 HDFS Write: 961 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 2 seconds 370 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">empno	ename	job	mgr	hiredate	sal	comm	deptno</span></span><br><span class="line"><span class="string">Time taken: 16.388 seconds</span></span><br></pre></td></tr></table></figure>
<p>从上面的mapreduce运行输出结果可以看出，已经根据deptno 动态分区了</p>
<h3 id="查询已导入数据"><a href="#查询已导入数据" class="headerlink" title="查询已导入数据"></a>查询已导入数据</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">0: jdbc:hive2://hadoop001:10000/default&gt; select * from emp_dynamic_partition ;</span><br><span class="line"></span><br><span class="line">+------------------------------+------------------------------+----------------------------+----------------------------+---------------------------------+----------------------------+-----------------------------+-------------------------------+--+</span><br><span class="line">| emp_dynamic_partition.empno  | emp_dynamic_partition.ename  | emp_dynamic_partition.job  | emp_dynamic_partition.mgr  | emp_dynamic_partition.hiredate  | emp_dynamic_partition.sal  | emp_dynamic_partition.comm  | emp_dynamic_partition.deptno  |</span><br><span class="line">+------------------------------+------------------------------+----------------------------+----------------------------+---------------------------------+----------------------------+-----------------------------+-------------------------------+--+</span><br><span class="line">| 7782                         | CLARK                        | MANAGER                    | 7839                       | 1981-6-9                        | 2450.0                     | NULL                        | 10                            |</span><br><span class="line">| 7839                         | KING                         | PRESIDENT                  | NULL                       | 1981-11-17                      | 5000.0                     | NULL                        | 10                            |</span><br><span class="line">| 7934                         | MILLER                       | CLERK                      | 7782                       | 1982-1-23                       | 1300.0                     | NULL                        | 10                            |</span><br><span class="line">| 7369                         | SMITH                        | CLERK                      | 7902                       | 1980-12-17                      | 800.0                      | NULL                        | 20                            |</span><br><span class="line">| 7566                         | JONES                        | MANAGER                    | 7839                       | 1981-4-2                        | 2975.0                     | NULL                        | 20                            |</span><br><span class="line">| 7788                         | SCOTT                        | ANALYST                    | 7566                       | 1987-4-19                       | 3000.0                     | NULL                        | 20                            |</span><br><span class="line">| 7876                         | ADAMS                        | CLERK                      | 7788                       | 1987-5-23                       | 1100.0                     | NULL                        | 20                            |</span><br><span class="line">| 7902                         | FORD                         | ANALYST                    | 7566                       | 1981-12-3                       | 3000.0                     | NULL                        | 20                            |</span><br><span class="line">| 7499                         | ALLEN                        | SALESMAN                   | 7698                       | 1981-2-20                       | 1600.0                     | 300.0                       | 30                            |</span><br><span class="line">| 7521                         | WARD                         | SALESMAN                   | 7698                       | 1981-2-22                       | 1250.0                     | 500.0                       | 30                            |</span><br><span class="line">| 7654                         | MARTIN                       | SALESMAN                   | 7698                       | 1981-9-28                       | 1250.0                     | 1400.0                      | 30                            |</span><br><span class="line">| 7698                         | BLAKE                        | MANAGER                    | 7839                       | 1981-5-1                        | 2850.0                     | NULL                        | 30                            |</span><br><span class="line">| 7844                         | TURNER                       | SALESMAN                   | 7698                       | 1981-9-8                        | 1500.0                     | 0.0                         | 30                            |</span><br><span class="line">| 7900                         | JAMES                        | CLERK                      | 7698                       | 1981-12-3                       | 950.0                      | NULL                        | 30                            |</span><br><span class="line">| 8888                         | HIVE                         | PROGRAM                    | 7839                       | 1988-1-23                       | 10300.0                    | NULL                        | NULL                          |</span><br><span class="line">+------------------------------+------------------------------+----------------------------+----------------------------+---------------------------------+----------------------------+-----------------------------+-------------------------------+--+</span><br></pre></td></tr></table></figure>
<p>再来看下HDFS上的文件，就更加清楚了</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 ~]$ hadoop dfs -ls /user/hive/warehouse/emp_dynamic_partition</span><br><span class="line">DEPRECATED: Use of this script to execute hdfs <span class="built_in">command</span> is deprecated.</span><br><span class="line">Instead use the hdfs <span class="built_in">command</span> <span class="keyword">for</span> it.</span><br><span class="line"></span><br><span class="line">Found 4 items</span><br><span class="line">drwxr-xr-x   - hadoop supergroup          0 2017-09-25 07:28 /user/hive/warehouse/emp_dynamic_partition/deptno=10</span><br><span class="line">drwxr-xr-x   - hadoop supergroup          0 2017-09-25 07:28 /user/hive/warehouse/emp_dynamic_partition/deptno=20</span><br><span class="line">drwxr-xr-x   - hadoop supergroup          0 2017-09-25 07:28 /user/hive/warehouse/emp_dynamic_partition/deptno=30</span><br><span class="line">drwxr-xr-x   - hadoop supergroup          0 2017-09-25 07:28 /user/hive/warehouse/emp_dynamic_partition/deptno=__HIVE_DEFAULT_PARTITION__</span><br></pre></td></tr></table></figure>
<p>到此，我们看到了动态分区的好处了</p>
<p>更多关于分区的介绍，可参考官方文档：<br><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-AddPartitions" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-AddPartitions</a></p>

  </section>

</article>

<section class="read-more">
     
        
            <div class="read-more-item">
                <span class="read-more-item-dim">最近的文章</span>
                <h2 class="post-list__post-title post-title"><a href="/Hive/Hive--metastore.html" title="Hive的元数据管理">Hive的元数据管理</a></h2>
                <p class="excerpt">
                
                我们知道，Hive的元数据并不存放在HDFS上，而是存放在传统的RDBMS中，典型的如MySQL，这里我们以MySQL为元数据库，结合1.1.0版本的Hive为例进行说明。连接上MySQL后可以看到Hive元数据对应的表有36个，以下是部分主要表的简要说明。



表名
说明
关联键




BUC
                &hellip;
                </p>
                <div class="post-list__meta"><time datetime="2017-10-09T09:38:12.000Z" class="post-list__meta--date date">2017-10-09</time>
 &#8226; <span class="post-list__meta--tags tags">于&nbsp;
  <a class="tag-link" href="/tags/Hive/">Hive</a>

</span><a class="btn-border-small" href="/Hive/Hive--metastore.html">继续阅读</a></div>

            </div>
        

        
            <div class="read-more-item">
                <span class="read-more-item-dim">更早的文章</span>
                <h2 class="post-list__post-title post-title"><a href="/Hive/Hive--DDL.html" title="Hive--数据库和表">Hive--数据库和表</a></h2>
                <p class="excerpt">
                
                本文介绍Hive的数据存储和一些常用DDL、DML操作
                &hellip;
                </p>
                <div class="post-list__meta"><time datetime="2017-10-08T10:23:30.000Z" class="post-list__meta--date date">2017-10-08</time>
 &#8226; <span class="post-list__meta--tags tags">于&nbsp;
  <a class="tag-link" href="/tags/Hive/">Hive</a>

</span><a class="btn-border-small" href="/Hive/Hive--DDL.html">继续阅读</a></div>

            </div>
        
   
</section>



<section class="post-comments">
  
<div id="cloud-tie-wrapper" class="cloud-tie-wrapper"></div>
<script src="https://img1.cache.netease.com/f2e/tie/yun/sdk/loader.js"></script>
<script>
var cloudTieConfig = {
  url: document.location.href, 
  sourceId: "",
  productKey: "7e456de65fb945698c448c72191454ce",
  target: "cloud-tie-wrapper"
};
var yunManualLoad = true;
Tie.loader("aHR0cHM6Ly9hcGkuZ2VudGllLjE2My5jb20vcGMvbGl2ZXNjcmlwdC5odG1s", true);
</script>

</section>





            <footer class="footer">
    <span class="footer__copyright">
        本站点采用<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>
    </span>
    <span class="footer__copyright">
        基于 <a href="http://hexo.io">Hexo</a> 搭建，感谢 <a href="https://pages.github.com/">GitHub Pages</a> 提供免费的托管服务
    </span>
    <span class="footer__copyright">
        &copy; 2018 - 本站由 <a href="/">XieJM</a> 创建,
        使用<a href="https://github.com/skx926/hexo-theme-vno">hexo-theme-vno</a>主题
    </span>
</footer>

        </div>
    </div>

    <script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
    <script src="/js/main.js"></script>

     
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-73055515-1', 'auto');
	ga('send', 'pageview');
</script>

</body>
</html>
