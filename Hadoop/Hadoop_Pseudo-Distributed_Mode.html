<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    
    <title>Hadoop伪分布式部署 | 云筑小站</title>
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <meta name="description" content="脚踏实地、仰望星空;低头走路，抬头看天;既练轻功，也练内功。">

    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Hadoop伪分布式部署 | 云筑小站">
    <meta name="twitter:description" content="脚踏实地、仰望星空;低头走路，抬头看天;既练轻功，也练内功。">

    <meta property="og:type" content="article">
    <meta property="og:title" content="Hadoop伪分布式部署 | 云筑小站">
    <meta property="og:description" content="脚踏实地、仰望星空;低头走路，抬头看天;既练轻功，也练内功。">

    
    <meta name="author" content="XieJM">
    
    <link rel="stylesheet" href="/css/vno.css">
    <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css">

    
    <link rel="icon" href="/images/favicon.png">
    

    
    <link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
    
    
    <meta name="generator" content="hexo"/>
    
    <link rel="alternate" type="application/rss+xml" title="云筑小站" href="/atom.xml">
    

    <link rel="canonical" href="http://xiejm.com/Hadoop/Hadoop_Pseudo-Distributed_Mode.html"/>

    
</head>

<body class="home-template no-js">

    <span class="mobile btn-mobile-menu">
        <i class="fa fa-list btn-mobile-menu__icon"></i>
        <i class="fa fa-angle-up btn-mobile-close__icon hidden"></i>
    </span>

    
<header class="panel-cover panel-cover--collapsed" style="background-image: url(/images/background-cover.jpg)">
  <div class="panel-main">
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        <a href="/" title="前往 云筑小站 的主页"><img src="/images/logo.png" width="80" alt="云筑小站 logo" class="panel-cover__logo logo" /></a>
        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage for 云筑小站">云筑小站</a></h1>
        
        <span class="panel-cover__subtitle panel-subtitle">分享技术 记录生活</span>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">脚踏实地、仰望星空;低头走路，抬头看天;既练轻功，也练内功。</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        
        <div class="navigation-wrapper">
          <div>
          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              <li class="navigation__item"><a href="/#blog" title="访问博客" class="blog-button">文章</a></li>
            
              <li class="navigation__item"><a href="/archives">归档</a></li>
            
            </ul>
          </nav>
          </div>
          <div>
          <nav class="cover-navigation navigation--social">
  <ul class="navigation">

  <!-- Weibo-->
  

  <!-- Github -->
  
  <li class="navigation__item">
    <a href="https://github.com/xjmhz" title="查看我的GitHub主页" target="_blank">
      <i class='social fa fa-github'></i>
      <span class="label">Github</span>
    </a>
  </li>


<!-- Stack Overflow -->
        

  <!-- Google Plus -->
  

<!-- Facebook -->


<!-- Twitter -->

<!-- instagram -->


  <li class="navigation__item">
    <a href="/atom.xml" title="RSS" target="_blank">
      <i class='social fa fa-rss'></i>
      <span class="label">RSS</span>
    </a>
  </li>



  </ul>
</nav>

          </div>
        </div>

      </div>

    </div>

    <div class="panel-cover--overlay cover-disabled"></div>
  </div>
</header>


    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <article class="post-container post-container--single">

  <header class="post-header">
    <div class="post-meta">
      <time datetime="2017-10-03T06:16:06.000Z" class="post-list__meta--date date">2017-10-03</time>
 &#8226; <span class="post-meta__tags tags">分类&nbsp;
  <a class="tag-link" href="/tags/Hadoop/">Hadoop</a>

</span>
    </div>
    <h1 class="post-title">Hadoop伪分布式部署</h1>
  </header>

  <section class="post">
    <p>本文主要记录Hadoop伪分布式（Pseudo-Distributed Mode）部署的详细步骤：<br>伪分布模式在“单节点集群”上运行Hadoop，其中所有的守护进程都运行在同一台机器上。该模式在单机模式之上增加了代码调试功能，允许你检查内存使用情况，HDFS输入输出，以及其他的守护进程交互。</p>
<h2 id="1-基本环境"><a href="#1-基本环境" class="headerlink" title="1.基本环境"></a>1.基本环境</h2><ul>
<li>CentOS 6.7</li>
<li>JDK1.7+</li>
<li>Hadoop 2.7.4</li>
</ul>
<blockquote>
<p>系统原始环境特别说明：<br>系统选择minimal最小系统安装，并自定义选装以下包：<br>Base System中的Base、Compatbillty libraries、Debugging Tools; Development中的 Development tools</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">[root@hadoop001 ~]<span class="comment"># service iptables stop</span></span><br><span class="line">iptables: Setting chains to policy ACCEPT: filter          [  OK  ]</span><br><span class="line">iptables: Flushing firewall rules:                         [  OK  ]</span><br><span class="line">iptables: Unloading modules:                               [  OK  ]</span><br><span class="line">[root@hadoop001 ~]<span class="comment"># chkconfig iptables off</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭SELINUX</span></span><br><span class="line">[root@hadoop001 ~]<span class="comment"># sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/config</span></span><br><span class="line"><span class="comment">#关闭当前的SELINUX状态,如果不用setenforce那么需要重启系统</span></span><br><span class="line">[root@hadoop001 ~]<span class="comment"># setenforce 0</span></span><br><span class="line">[root@hadoop001 ~]<span class="comment"># grep SELINUX=disabled /etc/selinux/config</span></span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure>
<h2 id="2-JDK安装"><a href="#2-JDK安装" class="headerlink" title="2.JDK安装"></a>2.JDK安装</h2><p>本文采用JDK1.7.79,详细安装步骤参考本博客的JDK安装的文章:<a href="http://xiejm.com/Linux/CentOS_setup_JDK.html">JDK安装</a></p>
<h2 id="3-创建Hadoop用户"><a href="#3-创建Hadoop用户" class="headerlink" title="3.创建Hadoop用户"></a>3.创建Hadoop用户</h2><p>增加ID号为1000的hadoopGroup,增加ID为2000的用户并加入hadoopGroup组</p>
<p>固定用户和组的ID号是为了用户和组的权限一致，我遇到过一次在两台机器上用户名和组名相同，ID号不同结果导致权限有问题</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]<span class="comment"># groupadd -g 1000 hadoopGroup</span></span><br><span class="line">[root@hadoop001 ~]<span class="comment"># useradd -u 2000 -g hadoopGroup hadoop</span></span><br></pre></td></tr></table></figure>
<p>设置hadoop用户的密码为hadoop，下面的这种方法免去了修改密码时的密码确认</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]<span class="comment"># echo "hadoop"|passwd --stdin hadoop</span></span><br></pre></td></tr></table></figure>
<p>设置hadoop用户sodu权限</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]<span class="comment"># vi /etc/sudoers</span></span><br><span class="line">hadoop ALL=(ALL)       ALL</span><br></pre></td></tr></table></figure>
<h2 id="4-上传（下载）解压Hadoop包"><a href="#4-上传（下载）解压Hadoop包" class="headerlink" title="4.上传（下载）解压Hadoop包"></a>4.上传（下载）解压Hadoop包</h2><p>hadoop-2.7.4.tar.gz包使用rz命令上传或通过wget命令去官网下载</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 ~]<span class="comment"># mkdir -p /opt/software</span></span><br><span class="line"><span class="comment">#将hadoop安装包放到/opt/software</span></span><br><span class="line">[root@hadoop001 ~]<span class="comment"># cd /opt/software</span></span><br><span class="line">[root@hadoop001 software]<span class="comment"># tar -zxvf hadoop-2.7.4.tar.gz</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#设置软连接</span></span><br><span class="line">[root@hadoop001 software]<span class="comment"># ln -s /opt/software/hadoop-2.7.4 /opt/software/hadoop</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#设置hadoop目录所有者、所属组</span></span><br><span class="line">[root@hadoop001 software]<span class="comment"># chown -R hadoop:hadoopGroup hadoop/*</span></span><br><span class="line">[root@hadoop001 software]<span class="comment"># chown -R hadoop:hadoopGroup hadoop-2.7.4</span></span><br><span class="line">[root@hadoop001 software]<span class="comment"># chown -R hadoop:hadoopGroup hadoop-2.7.4/*</span></span><br></pre></td></tr></table></figure>
<h2 id="5-配置环境变量"><a href="#5-配置环境变量" class="headerlink" title="5.配置环境变量"></a>5.配置环境变量</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@hadoop001 software]<span class="comment"># vim /etc/profile</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#按组合键shift+g 或大写G 到最后一行，按字母o  插入下列内容</span></span><br><span class="line">    <span class="comment">#SET HADOOP</span></span><br><span class="line">    exprot HADOOP_HOME=/opt/software/hadoop</span><br><span class="line"><span class="comment">#如果JDK环境变量没有配置，请加入下列内容</span></span><br><span class="line">    <span class="comment">#SET JDK</span></span><br><span class="line">    <span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.7.0_79</span><br><span class="line">    <span class="built_in">export</span> JRE_HOME=<span class="variable">$JAVA_HOME</span>/jre</span><br><span class="line">    <span class="built_in">export</span> CLASS_PATH=.:<span class="variable">$JAVA_HOME</span>/lib:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置PATH</span></span><br><span class="line">    <span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:<span class="variable">$&#123;JRE_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加完成后  :wq 保存</span></span><br><span class="line"><span class="comment">#使修改生效：</span></span><br><span class="line">[root@hadoop001 software]<span class="comment">#source !$</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#验证JDK有效性</span></span><br><span class="line">[root@hadoop001 software]<span class="comment"># java -version</span></span><br><span class="line">java version <span class="string">"1.7.0_79"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.7.0_79-b15)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)</span><br></pre></td></tr></table></figure>
<h2 id="6-配置SSH"><a href="#6-配置SSH" class="headerlink" title="6.配置SSH"></a>6.配置SSH</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#检查sshd</span></span><br><span class="line">[root@hadoop001 software]<span class="comment"># service sshd status</span></span><br><span class="line">openssh-daemon (pid  1844) is running...</span><br><span class="line">[root@hadoop001 software]<span class="comment"># su - hadoop</span></span><br><span class="line"></span><br><span class="line">[hadoop@hadoop001 ~]<span class="comment"># cd /opt/software/hadoop</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#SSH 免密设置</span></span><br><span class="line"><span class="comment">#由于是伪分布式需要用到ssh localhost的情况，所以需要在本机生成公钥</span></span><br><span class="line">[hadoop@hadoop001 hadoop]$ ssh-keygen -t rsa -P <span class="string">''</span> -f ~/.ssh/id_rsa</span><br><span class="line">[hadoop@hadoop001 hadoop]$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">[hadoop@hadoop001 hadoop]$ chmod 0600 ~/.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证SSH</span></span><br><span class="line">[hadoop@hadoop001 hadoop]<span class="variable">$ssh</span> hadoop001 date</span><br><span class="line">The authenticity of host <span class="string">'hadoop001 (192.168.137.130)'</span> can<span class="string">'t be established.</span></span><br><span class="line"><span class="string">RSA key fingerprint is 09:f6:4a:f1:a0:bd:79:fd:34:e7:75:94:0b:3c:83:5a.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes   #第一次回车输入yes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Warning: Permanently added '</span>hadoop001,192.168.137.130<span class="string">' (RSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">Sun Aug 20 14:22:28 CST 2017</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[hadoop@hadoop001 hadoop]$ssh hadoop001 date   #不需要回车输入yes,即SSH配置成功</span></span><br><span class="line"><span class="string">Sun Aug 20 14:22:29 CST 2017</span></span><br></pre></td></tr></table></figure>
<h2 id="7-配置core-site-xml"><a href="#7-配置core-site-xml" class="headerlink" title="7.配置core-site.xml"></a>7.配置core-site.xml</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/core-site.xml</span><br><span class="line"><span class="comment">#配置HDFS地址</span></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://hadoop001:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h2 id="8-配置hdfs-site-xml"><a href="#8-配置hdfs-site-xml" class="headerlink" title="8.配置hdfs-site.xml"></a>8.配置hdfs-site.xml</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/hdfs-site.xml</span><br><span class="line"><span class="comment">#配置HDFS副本数</span></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop001:50090&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.https-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hadoop001:50091&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h2 id="9-修改mapred-site-xml"><a href="#9-修改mapred-site-xml" class="headerlink" title="9.修改mapred-site.xml"></a>9.修改mapred-site.xml</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ vi etc/hadoop/mapred-site.xml:</span><br><span class="line"><span class="comment">#设置mapreduce框架为yarn</span></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h2 id="10-修改yarn-site-xml"><a href="#10-修改yarn-site-xml" class="headerlink" title="10.修改yarn-site.xml"></a>10.修改yarn-site.xml</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ etc/hadoop/yarn-site.xml:</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h2 id="11-修改slave文件"><a href="#11-修改slave文件" class="headerlink" title="11.修改slave文件"></a>11.修改slave文件</h2><p>将本机的主机名写入slave节点</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ehco <span class="string">'hadoop001'</span> &gt;/opt/software/hadoop/etc/hadooop/slave</span><br></pre></td></tr></table></figure>
<h2 id="12-启动HDFS和YARN"><a href="#12-启动HDFS和YARN" class="headerlink" title="12.启动HDFS和YARN"></a>12.启动HDFS和YARN</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#添加环境变量</span></span><br><span class="line">[hadoop@hadoop001 hadoop]$  vi etc/hadoop/hadoop-env.sh</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.7.0_79</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop001 hadoop]$ <span class="built_in">which</span> hdfs</span><br><span class="line">/opt/software/hadoop/bin/hdfs</span><br><span class="line">[hadoop@hadoop001 hadoop]$ hdfs namenode -format</span><br><span class="line">........</span><br><span class="line">17/08/20 16:43:19 INFO common.Storage: Storage directory</span><br><span class="line">/tmp/hadoop-hadoop/dfs/name has been successfully formatted.</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop001 hadoop]$ <span class="built_in">which</span> start-dfs.sh</span><br><span class="line">/opt/software/hadoop/sbin/start-dfs.sh</span><br><span class="line">[hadoop@hadoop001 hadoop]$</span><br><span class="line">[hadoop@hadoop001 hadoop]$ start-dfs.sh</span><br><span class="line">[hadoop@hadoop001 hadoop]$ sbin/start-yarn.sh</span><br><span class="line">[hadoop@hadoop001 hadoop]$ sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
<p>如果要结束进程，使用如下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ sbin/stop-yarn.sh</span><br><span class="line">[hadoop@hadoop001 hadoop]$ stop-dfs.sh</span><br><span class="line">[hadoop@hadoop001 hadoop]$ sbin/mr-jobhistory-daemon.sh stop historyserver</span><br></pre></td></tr></table></figure>
<h2 id="13-检查启动进程"><a href="#13-检查启动进程" class="headerlink" title="13.检查启动进程"></a>13.检查启动进程</h2><p>通过jps命令查看</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[hadoop@hadoop001 hadoop]$ jps</span><br><span class="line">19536 DataNode</span><br><span class="line">19440 NameNode</span><br><span class="line">19876 Jps</span><br><span class="line">19740 SecondaryNameNode</span><br><span class="line">19888 ResourceManager</span><br><span class="line">19345 NodeManager</span><br><span class="line">4613 JobHistoryServer</span><br></pre></td></tr></table></figure>
<p>通过WebUI查看</p>
<blockquote>
<p>Browse the web interface for the NameNode - <a href="http://hadoop001:50070/" target="_blank" rel="noopener"></a><br>Browse the web interface for the ResourceManager - <a href="http://hadoop001:8088/" target="_blank" rel="noopener"></a></p>
</blockquote>
<h2 id="14-验证MapReduce"><a href="#14-验证MapReduce" class="headerlink" title="14.验证MapReduce"></a>14.验证MapReduce</h2><p>我们使用hadoop 的mapreduce-examples  jar包来计算PI</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Run a MapReduce job.</span></span><br><span class="line">[hadoop@hadoop001 mapreduce]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/software/hadoop/share/hadoop/mapreduce</span><br><span class="line">[hadoop@hadoop002 mapreduce]$</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop002 mapreduce]$ ll</span><br><span class="line">-rw-r--r--. 1 hadoop hadoop  301740 Aug 20 15:12 hadoop-mapreduce-examples-2.7.4.jar</span><br><span class="line">[hadoop@hadoop002 mapreduce]$ hadoop jar hadoop-mapreduce-examples-2.7.4.jar pi 5 10</span><br></pre></td></tr></table></figure>
<h2 id="15-参考资料"><a href="#15-参考资料" class="headerlink" title="15.参考资料"></a>15.参考资料</h2><p> <a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="noopener">Setting up a Single Node Cluster：</a></p>

  </section>

</article>

<section class="read-more">
     
        
            <div class="read-more-item">
                <span class="read-more-item-dim">最近的文章</span>
                <h2 class="post-list__post-title post-title"><a href="/Linux/Extended_VM Disk_In_ VMware.html" title="Linux Extended VM Disk In VMware">Linux Extended VM Disk In VMware</a></h2>
                <p class="excerpt">
                
                前言在做大数据相关开发的测试时候，会用到VM虚拟机。用了时间久了以后，虚拟机磁盘爆满，这时就需要给虚拟机磁盘扩容了。
由于在当初创建虚拟机时选择了LVM分区，给现在扩容带来了便利。
                &hellip;
                </p>
                <div class="post-list__meta"><time datetime="2017-10-03T11:59:04.000Z" class="post-list__meta--date date">2017-10-03</time>
 &#8226; <span class="post-list__meta--tags tags">于&nbsp;
  <a class="tag-link" href="/tags/Linux/">Linux</a>

</span><a class="btn-border-small" href="/Linux/Extended_VM Disk_In_ VMware.html">继续阅读</a></div>

            </div>
        

        
            <div class="read-more-item">
                <span class="read-more-item-dim">更早的文章</span>
                <h2 class="post-list__post-title post-title"><a href="/Hive/Hive--install.html" title="Hive--安装">Hive--安装</a></h2>
                <p class="excerpt">
                
                本文主要是Hive部署的详细步骤
1.基本环境
CentOS 6.7
JDK1.8
Hadoop-2.6.0-cdh5.7.0
Hive-1.1.0-cdh5.7.0

Hive是基于Hadoop的，Hadoop的部署本文不在复述。
2.上传解压tar -zxvf Hive-1.1.0-cdh5.7
                &hellip;
                </p>
                <div class="post-list__meta"><time datetime="2017-10-02T15:44:44.000Z" class="post-list__meta--date date">2017-10-02</time>
 &#8226; <span class="post-list__meta--tags tags">于&nbsp;
  <a class="tag-link" href="/tags/Hive/">Hive</a>

</span><a class="btn-border-small" href="/Hive/Hive--install.html">继续阅读</a></div>

            </div>
        
   
</section>



<section class="post-comments">
  
<div id="cloud-tie-wrapper" class="cloud-tie-wrapper"></div>
<script src="https://img1.cache.netease.com/f2e/tie/yun/sdk/loader.js"></script>
<script>
var cloudTieConfig = {
  url: document.location.href, 
  sourceId: "",
  productKey: "7e456de65fb945698c448c72191454ce",
  target: "cloud-tie-wrapper"
};
var yunManualLoad = true;
Tie.loader("aHR0cHM6Ly9hcGkuZ2VudGllLjE2My5jb20vcGMvbGl2ZXNjcmlwdC5odG1s", true);
</script>

</section>





            <footer class="footer">
    <span class="footer__copyright">
        本站点采用<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>
    </span>
    <span class="footer__copyright">
        基于 <a href="http://hexo.io">Hexo</a> 搭建，感谢 <a href="https://pages.github.com/">GitHub Pages</a> 提供免费的托管服务
    </span>
    <span class="footer__copyright">
        &copy; 2018 - 本站由 <a href="/">XieJM</a> 创建,
        使用<a href="https://github.com/skx926/hexo-theme-vno">hexo-theme-vno</a>主题
    </span>
</footer>

        </div>
    </div>

    <script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
    <script src="/js/main.js"></script>

     
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-73055515-1', 'auto');
	ga('send', 'pageview');
</script>

</body>
</html>
